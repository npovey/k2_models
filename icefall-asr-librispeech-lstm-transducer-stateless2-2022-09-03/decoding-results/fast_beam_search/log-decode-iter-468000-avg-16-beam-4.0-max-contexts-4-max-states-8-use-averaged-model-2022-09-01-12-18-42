2022-09-01 12:18:42,164 INFO [decode.py:663] Decoding started
2022-09-01 12:18:42,164 INFO [decode.py:669] Device: cuda:0
2022-09-01 12:18:42,167 INFO [decode.py:679] {'best_train_loss': inf, 'best_valid_loss': inf, 'best_train_epoch': -1, 'best_valid_epoch': -1, 'batch_idx_train': 0, 'log_interval': 50, 'reset_interval': 200, 'valid_interval': 3000, 'feature_dim': 80, 'subsampling_factor': 4, 'dim_feedforward': 2048, 'decoder_dim': 512, 'joiner_dim': 512, 'model_warm_step': 3000, 'env_info': {'k2-version': '1.15.1', 'k2-build-type': 'Release', 'k2-with-cuda': True, 'k2-git-sha1': 'f8d2dba06c000ffee36aab5b66f24e7c9809f116', 'k2-git-date': 'Thu Apr 21 12:20:34 2022', 'lhotse-version': '1.3.0.dev+missing.version.file', 'torch-version': '1.10.0+cu102', 'torch-cuda-available': True, 'torch-cuda-version': '10.2', 'python-version': '3.8', 'icefall-git-branch': 'lstm-giga-libri', 'icefall-git-sha1': 'e3128cb-dirty', 'icefall-git-date': 'Mon Aug 29 19:05:41 2022', 'icefall-path': '/k2-dev/fangjun/open-source/icefall-lstm-giga', 'k2-path': '/ceph-fj/fangjun/open-source-2/k2-multi-22/k2/python/k2/__init__.py', 'lhotse-path': '/ceph-fj/fangjun/open-source-2/lhotse-jsonl/lhotse/__init__.py', 'hostname': 'de-74279-k2-train-2-0602201035-5fb6d86964-mclm7', 'IP address': '10.177.74.202'}, 'epoch': 30, 'iter': 468000, 'avg': 16, 'use_averaged_model': True, 'exp_dir': PosixPath('lstm_transducer_stateless2/exp'), 'bpe_model': 'data/lang_bpe_500/bpe.model', 'lang_dir': PosixPath('data/lang_bpe_500'), 'decoding_method': 'fast_beam_search', 'beam_size': 4, 'beam': 4.0, 'ngram_lm_scale': 0.01, 'max_contexts': 4, 'max_states': 8, 'context_size': 2, 'max_sym_per_frame': 1, 'num_paths': 200, 'nbest_scale': 0.5, 'num_encoder_layers': 12, 'encoder_dim': 512, 'rnn_hidden_size': 1024, 'aux_layer_period': 0, 'max_duration': 600, 'bucketing_sampler': True, 'num_buckets': 30, 'shuffle': True, 'return_cuts': True, 'num_workers': 2, 'on_the_fly_num_workers': 0, 'enable_spec_aug': True, 'spec_aug_time_warp_factor': 80, 'enable_musan': True, 'manifest_dir': PosixPath('data/fbank'), 'on_the_fly_feats': False, 'res_dir': PosixPath('lstm_transducer_stateless2/exp/fast_beam_search'), 'suffix': 'iter-468000-avg-16-beam-4.0-max-contexts-4-max-states-8-use-averaged-model', 'blank_id': 0, 'unk_id': 2, 'vocab_size': 500}
2022-09-01 12:18:42,167 INFO [decode.py:681] About to create model
2022-09-01 12:18:42,546 INFO [train.py:464] Disable giga
2022-09-01 12:18:42,559 INFO [decode.py:735] Calculating the averaged model over iteration checkpoints from lstm_transducer_stateless2/exp/checkpoint-436000.pt (excluded) to lstm_transducer_stateless2/exp/checkpoint-468000.pt
2022-09-01 12:18:48,456 INFO [decode.py:791] Number of model parameters: 84689496
2022-09-01 12:18:48,456 INFO [librispeech.py:58] About to get test-clean cuts from data/fbank/librispeech_cuts_test-clean.jsonl.gz
2022-09-01 12:18:48,459 INFO [librispeech.py:63] About to get test-other cuts from data/fbank/librispeech_cuts_test-other.jsonl.gz
2022-09-01 12:18:50,915 INFO [decode.py:565] batch 0/?, cuts processed until now is 27
2022-09-01 12:19:14,887 INFO [decode.py:565] batch 20/?, cuts processed until now is 1623
2022-09-01 12:19:32,610 INFO [decode.py:565] batch 40/?, cuts processed until now is 2468
2022-09-01 12:19:45,959 INFO [decode.py:583] The transcripts are stored in lstm_transducer_stateless2/exp/fast_beam_search/recogs-test-clean-beam_4.0_max_contexts_4_max_states_8-iter-468000-avg-16-beam-4.0-max-contexts-4-max-states-8-use-averaged-model.txt
2022-09-01 12:19:46,027 INFO [utils.py:428] [test-clean-beam_4.0_max_contexts_4_max_states_8] %WER 2.76% [1451 / 52576, 168 ins, 103 del, 1180 sub ]
2022-09-01 12:19:46,197 INFO [decode.py:596] Wrote detailed error stats to lstm_transducer_stateless2/exp/fast_beam_search/errs-test-clean-beam_4.0_max_contexts_4_max_states_8-iter-468000-avg-16-beam-4.0-max-contexts-4-max-states-8-use-averaged-model.txt
2022-09-01 12:19:46,197 INFO [decode.py:613] 
For test-clean, WER of different settings are:
beam_4.0_max_contexts_4_max_states_8	2.76	best for test-clean

2022-09-01 12:19:48,304 INFO [decode.py:565] batch 0/?, cuts processed until now is 31
2022-09-01 12:20:10,671 INFO [decode.py:565] batch 20/?, cuts processed until now is 1849
2022-09-01 12:20:26,708 INFO [decode.py:565] batch 40/?, cuts processed until now is 2785
2022-09-01 12:20:38,829 INFO [decode.py:583] The transcripts are stored in lstm_transducer_stateless2/exp/fast_beam_search/recogs-test-other-beam_4.0_max_contexts_4_max_states_8-iter-468000-avg-16-beam-4.0-max-contexts-4-max-states-8-use-averaged-model.txt
2022-09-01 12:20:38,900 INFO [utils.py:428] [test-other-beam_4.0_max_contexts_4_max_states_8] %WER 7.31% [3827 / 52343, 397 ins, 383 del, 3047 sub ]
2022-09-01 12:20:39,117 INFO [decode.py:596] Wrote detailed error stats to lstm_transducer_stateless2/exp/fast_beam_search/errs-test-other-beam_4.0_max_contexts_4_max_states_8-iter-468000-avg-16-beam-4.0-max-contexts-4-max-states-8-use-averaged-model.txt
2022-09-01 12:20:39,118 INFO [decode.py:613] 
For test-other, WER of different settings are:
beam_4.0_max_contexts_4_max_states_8	7.31	best for test-other

2022-09-01 12:20:39,118 INFO [decode.py:823] Done!
